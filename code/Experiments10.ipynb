{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score, auc, roc_auc_score, log_loss, mean_squared_error, r2_score\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from rit.tree import DecisionTreeClassifier as MyDecisionTreeClassifier\n",
    "from rit.tree import DecisionTreeRegressor as MyDecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from rit.ensemble import RandomForestClassifier as MyRandomForestClassifier\n",
    "from rit.ensemble import RandomForestRegressor as MyRandomForestRegressor\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import clone\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from model import CustomBoost\n",
    "\n",
    "from functions import *\n",
    "from gendata import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 6\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams['font.size'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uniform, noncentered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_1()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_1 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha, True)\n",
    "    arr_1.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ilia/all_feature_importance/examples/model.py:111: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = f.grad.cpu().numpy() * X.shape[0]\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n18 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ilia/all_feature_importance/examples/model.py\", line 112, in fit\n    clf.fit(X, -gradient)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py\", line 1406, in fit\n    super()._fit(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py\", line 255, in _fit\n    X, y = self._validate_data(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py\", line 620, in _validate_data\n    y = check_array(y, input_name=\"y\", **check_y_params)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains infinity or a value too large for dtype('float32').\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m arr_5 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alphas[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     cb \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     arr_5\u001b[38;5;241m.\u001b[39mappend(r2_score(y_test, cb\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[0;32m~/all_feature_importance/examples/functions.py:326\u001b[0m, in \u001b[0;36mfunc_cb\u001b[0;34m(X, y, alpha, task)\u001b[0m\n\u001b[1;32m    318\u001b[0m cv \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(X_train)\n\u001b[1;32m    319\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(CustomBoost(base_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m                                n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m    321\u001b[0m                                task\u001b[38;5;241m=\u001b[39mtask),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m                cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    325\u001b[0m                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 326\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m cb \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    328\u001b[0m cb\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n18 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ilia/all_feature_importance/examples/model.py\", line 112, in fit\n    clf.fit(X, -gradient)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py\", line 1406, in fit\n    super()._fit(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py\", line 255, in _fit\n    X, y = self._validate_data(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py\", line 620, in _validate_data\n    y = check_array(y, input_name=\"y\", **check_y_params)\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains infinity or a value too large for dtype('float32').\n"
     ]
    }
   ],
   "source": [
    "X, y = data_regression_2D_5()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_5 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha, True)\n",
    "    arr_5.append(r2_score(y_test, cb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gauss, centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_2()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_2 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_2.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_6()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_6 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_6.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uniform, centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_3()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_3 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_3.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_7()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_7 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_7.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gauss, noncentered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_4()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_4 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_4.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_8()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_8 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha)\n",
    "    arr_8.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification, unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ilia/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m arr_9 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alphas[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     cb \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_cb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     arr_9\u001b[38;5;241m.\u001b[39mappend(accuracy_score(cb\u001b[38;5;241m.\u001b[39mpredict(X_test), y_test))\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mfunc_cb\u001b[0;34m(X, y, alpha, task)\u001b[0m\n\u001b[1;32m      4\u001b[0m cv \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(X_train)\n\u001b[1;32m      5\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(CustomBoost(base_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                                n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                task \u001b[38;5;241m=\u001b[39m task),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m     11\u001b[0m                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m cb \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     14\u001b[0m cb\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/all_feature_importance/examples/model.py:114\u001b[0m, in \u001b[0;36mCustomBoost.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    111\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    112\u001b[0m gradient \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 114\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfin_i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clf\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mnode_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py:1406\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \n\u001b[1;32m   1380\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1406\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/all_feature_importance/venv/lib/python3.9/site-packages/rit-0.1.0-py3.9-linux-x86_64.egg/rit/tree/_classes.py:469\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# === RIT === end\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    460\u001b[0m         splitter,\n\u001b[1;32m    461\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 469\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = data_classification_2D_3()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_9 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha, \"Classification\")\n",
    "    arr_9.append(accuracy_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_classification_2D_4()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alphas = [-10000, 0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.91, 0.93, 0.95, 0.99, 0.999, 0.9999, 0.99999, 0.999999, 1]\n",
    "arr_10 = []\n",
    "for alpha in alphas[:-1]:\n",
    "    cb = func_cb(X, y, alpha, \"Classification\")\n",
    "    arr_10.append(accuracy_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_regression_2D_1()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "depths = [i for i in range(1, 5)]\n",
    "arr_scores = []\n",
    "for depth in depths:\n",
    "    cb = CustomBoost(rit_alpha=0.5, max_depth=depth)\n",
    "    cb.fit(X_train, y_train)\n",
    "    arr_scores.append(r2_score(cb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004091055587354786"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data_regression_2D_1()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cb = CustomBoost(base_estimator=None, rit_alpha=0.5, max_depth=5, task=True)\n",
    "cb.fit(X_train, y_train)\n",
    "r2_score(cb.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_classification_2D_3()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "cb = CustomBoost(base_estimator=None, rit_alpha=-10000, max_depth=5, task=False)\n",
    "cb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'> <class 'numpy.int64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8694444444444445"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(cb.predict(X_test)[0]), type(y_test[0]))\n",
    "accuracy_score(cb.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None make_scorer(accuracy_score)\n",
      "[1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1\n",
      " 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0\n",
      " 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0] [1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 1\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0]\n",
      "rit_alpha = -10000, max_depth = 6, nu = 0.001, score = 0.8527777777777777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8527777777777777"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data_classification_2D_4()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "alpha = -10000\n",
    "cb = func_cb(X, y, alpha, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
